{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eae42925-52ef-42fc-97c9-5a1fcbe32e67",
   "metadata": {
    "id": "eae42925-52ef-42fc-97c9-5a1fcbe32e67"
   },
   "source": [
    "# Lane Segmentation via BeamNG from existing map\n",
    "\n",
    "BeamNG.tech provides an out-of-the-box solution for gathering segmentation data with special render settings for more optimal data collection. Unfortunately, the map that we attempted to use this on does not work well with default techniques (the track is one large model, meaning object annotation does not give what we want, and material annotation is currently not working with the given map). Therefore, we devised a novel procedure to collect accurate base and annotated image pairs using BeamNGpy and the world editor (F11).\n",
    "\n",
    "**Prerequisite: Map with transparent mesh road that follows the track wanted (see below):**\n",
    "\n",
    "Base Image:\n",
    "\n",
    "<img src=\"images/track.PNG\"  width=\"40%\" height=\"40%\" />\n",
    "\n",
    "\n",
    "Image with Exposed Track:\n",
    "\n",
    "<img src=\"images/no_track.PNG\"  width=\"40%\" height=\"40%\" />\n",
    "\n",
    "_Disclaimer: If there are updates, the package will always be more up-to-date than this notebook._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b3c7a-2461-406f-9f7e-9ac68f5635d0",
   "metadata": {
    "id": "500b3c7a-2461-406f-9f7e-9ac68f5635d0"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from beamngpy import BeamNGpy, Scenario, Vehicle\n",
    "from beamngpy.sensors import Camera\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import beamngpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Setup variables\n",
    "home_dir = r'C:\\Users\\jazzy\\Desktop\\BeamNG'\n",
    "user_dir = r'C:\\Users\\jazzy\\Desktop\\BeamNG'\n",
    "\n",
    "# Scenario variables\n",
    "map = 'rb_ks_monza'\n",
    "annotated_map = 'rb_ks_monza_annotated'\n",
    "car_model = '2022__4_navaro_ssr_700_indycar'\n",
    "start_pos = (-177.105, -107.766, 154.945)\n",
    "start_rot_quat = (0, 0, -0.998, 0.0598)\n",
    "\n",
    "# BeamNG.* instance (server)\n",
    "bng = BeamNGpy('localhost', 64526, home=home_dir, user=user_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FOe0mNn5ayWt",
   "metadata": {
    "id": "FOe0mNn5ayWt"
   },
   "outputs": [],
   "source": [
    "# Start BeamNG server and simulator\n",
    "bng.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DlmcZhvWhW-L",
   "metadata": {
    "id": "DlmcZhvWhW-L"
   },
   "outputs": [],
   "source": [
    "# Reconnect to an open simulator\n",
    "bng.open(launch=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "GLYpV8BpRcrC",
   "metadata": {
    "id": "GLYpV8BpRcrC"
   },
   "source": [
    "# Recording points from car\n",
    "\n",
    "The way this workaround works is by teleporting the car randomly to a valid point, as defined by the user. One way to do this is to record points from a car's path, and then define a radius from this point such that any point within that radius is valid. The code below produces these points from a car's path, as controlled by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8RimGawIS29V",
   "metadata": {
    "id": "8RimGawIS29V"
   },
   "outputs": [],
   "source": [
    "def record_points_from_car(v: Vehicle, interval=1, countdown = True):\n",
    "  points = []\n",
    "  if countdown:\n",
    "    for i in range(5, -1, -1):\n",
    "      print(\"Starting in \" + str(i) + \"...\")\n",
    "      time.sleep(1)\n",
    "  print(\"Press CTRL+C to stop recording...\")\n",
    "  try:\n",
    "    while True:\n",
    "      points.append(v.get_center_of_gravity())\n",
    "      time.sleep(interval)\n",
    "  except KeyboardInterrupt:\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aazYVUmYVnIL",
   "metadata": {
    "id": "aazYVUmYVnIL"
   },
   "outputs": [],
   "source": [
    "# Scenario for recording\n",
    "scenario = Scenario(map, \"record points\")\n",
    "car0 = Vehicle('car0', model=car_model)\n",
    "scenario.add_vehicle(car0, pos=start_pos, rot_quat=start_rot_quat)\n",
    "\n",
    "scenario.make(bng)\n",
    "bng.scenario.load(scenario)\n",
    "bng.scenario.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AzXXy2FZXHAP",
   "metadata": {
    "id": "AzXXy2FZXHAP"
   },
   "outputs": [],
   "source": [
    "# Record points\n",
    "recorded_points = record_points_from_car(car0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c-7sCRa3SVkP",
   "metadata": {
    "id": "c-7sCRa3SVkP"
   },
   "source": [
    "# Defining function for random point generation\n",
    "\n",
    "The function for random point generation is custom based on the use case, but the default implementation takes the output from recording the points from the user-controlled car and finds points within a radius of any of the generated points.\n",
    "\n",
    "_Replace this function if you want to use your own custom implementation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h7fgEm-vS1gJ",
   "metadata": {
    "id": "h7fgEm-vS1gJ"
   },
   "outputs": [],
   "source": [
    "def generate_random_point(points, radius=4): # not optimized\n",
    "  point = random.choice(points)\n",
    "  offsets = (random.uniform(-radius, radius), random.uniform(-radius, radius), 0.5)\n",
    "  rot_quat = beamngpy.quat.angle_to_quat((0, 0, random.uniform(-180, 180)))\n",
    "  return (point[0] + offsets[0], point[1] + offsets[1], point[2] + offsets[2]), rot_quat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2hJN7ctSPVq",
   "metadata": {
    "id": "e2hJN7ctSPVq"
   },
   "source": [
    "# Generating images\n",
    "\n",
    "To generate images, we capture images twice: once with a clear track as a base image and one with an opaque track as an annotated image. To do this, we keep track of where we want to capture images in the simulator. We do this here by recording points off a valid path, then taking points off a radius from that path.\n",
    "\n",
    "_This is because annotation rendering takes into account material opacity, so the track won't show up in the annotated image when the track is clear, but we need it to be to capture track details._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zuh70V_afGV2",
   "metadata": {
    "id": "zuh70V_afGV2"
   },
   "outputs": [],
   "source": [
    "# Number of image pairs we want to create\n",
    "n = 10\n",
    "\n",
    "# Create list of locations and directions to capture images on the track\n",
    "track_points = recorded_points\n",
    "locations = [generate_random_point(track_points) for _ in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XUxdN52KpO49",
   "metadata": {
    "id": "XUxdN52KpO49"
   },
   "outputs": [],
   "source": [
    "# Start scenario if not started already\n",
    "scenario = Scenario(map, \"base track\")\n",
    "car0 = Vehicle('car0', model=car_model)\n",
    "scenario.add_vehicle(car0, pos=start_pos, rot_quat=start_rot_quat)\n",
    "\n",
    "scenario.make(bng)\n",
    "bng.scenario.load(scenario)\n",
    "bng.scenario.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "BSo4k9tVm3j3",
   "metadata": {
    "id": "BSo4k9tVm3j3"
   },
   "source": [
    "## Define camera setup\n",
    "\n",
    "Define camera setup to allow for multiple cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_FGEyZegnDNt",
   "metadata": {
    "id": "_FGEyZegnDNt"
   },
   "outputs": [],
   "source": [
    "camera_positions = [\n",
    "    ((-0.3, 1, 2), (0, -1, 0), (0, 0, 1), 70)\n",
    "] # add tuples with pos, dir, up, fov [both in (x, y, z) format]\n",
    "\n",
    "# Attach cameras to car\n",
    "def attach_cameras(camera_positions, v: Vehicle, near_far_planes=(0.1, 1000), resolution=(224, 224)):\n",
    "  cameras = []\n",
    "  for i, (pos, dir, up, fov) in enumerate(camera_positions):\n",
    "    camera = Camera('camera' + str(i), bng, v, requested_update_time=-1.0, is_using_shared_memory=False,\n",
    "                    pos=pos, dir=dir, up=up,\n",
    "                    field_of_view_y=fov, near_far_planes=near_far_planes, resolution=resolution,\n",
    "                    is_render_annotations=True, is_render_instance=True, is_render_depth=True)\n",
    "    cameras.append(camera)\n",
    "  return cameras\n",
    "\n",
    "cameras = attach_cameras(camera_positions, car0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Hk3YYe_npb_-",
   "metadata": {
    "id": "Hk3YYe_npb_-"
   },
   "source": [
    "## Generate base and annotated images\n",
    "\n",
    "At this point, the mesh road defining the track should be transparent. One can do this in the world editor by setting the corresponding material's opacity to 0.\n",
    "\n",
    "_This is done via the material alpha, make sure to enable `Alpha Clip` under `Advanced - All Layers` in the material editor._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m5ymuInRptQ0",
   "metadata": {
    "id": "m5ymuInRptQ0"
   },
   "outputs": [],
   "source": [
    "def generate_images(v: Vehicle, locations, cameras, annotated = False):\n",
    "  images = {}\n",
    "  for i, (pos, dir) in tqdm(enumerate(locations)):\n",
    "    v.teleport(pos, rot_quat=dir)\n",
    "    for j, cam in enumerate(cameras):\n",
    "      base_image = cam.get_full_poll_request()['colour' if not annotated else 'annotation']\n",
    "      name = \"{}_{}\".format(i, j)\n",
    "      images[name] = base_image\n",
    "  return images\n",
    "\n",
    "base_images = generate_images(car0, locations, cameras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "M8uKijlj1R9H",
   "metadata": {
    "id": "M8uKijlj1R9H"
   },
   "source": [
    "## Generate annotated images\n",
    "\n",
    "At this point, the mesh road defining the track should be opaque. Save the track on the scenario so you can automate the entire process. Check that the track is properly annotated with the block below. **Ensure that the material 'Empty' has the `STREET` annotation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch scenarios\n",
    "scenario = Scenario(annotated_map, \"annotated track\")\n",
    "car0 = Vehicle('car0', model=car_model)\n",
    "scenario.add_vehicle(car0, pos=start_pos, rot_quat=start_rot_quat)\n",
    "\n",
    "scenario.make(bng)\n",
    "bng.scenario.load(scenario)\n",
    "bng.scenario.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if image is annotated correctly\n",
    "images = cameras[0].get_full_poll_request()\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(images['colour'])\n",
    "ax[1].imshow(images['annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NjGvPmn81r3n",
   "metadata": {
    "id": "NjGvPmn81r3n"
   },
   "outputs": [],
   "source": [
    "annotated_images = generate_images(car0, locations, cameras, annotated = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "mTvFn2J3Ni_h",
   "metadata": {
    "id": "mTvFn2J3Ni_h"
   },
   "source": [
    "## Pair images\n",
    "\n",
    "After generating base and annotated images with the same locations and camera setup, we pair the images together to get base and labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "erUdQE-cNilc",
   "metadata": {
    "id": "erUdQE-cNilc"
   },
   "outputs": [],
   "source": [
    "def pair_images(base: dict, annotated: dict):\n",
    "  images = {}\n",
    "  for name in base:\n",
    "    images[name] = {'base': base[name], 'annotated': annotated[name]}\n",
    "  return images\n",
    "\n",
    "paired_images = pair_images(base_images, annotated_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "vdQu9B3POQHy",
   "metadata": {
    "id": "vdQu9B3POQHy"
   },
   "source": [
    "## Save images\n",
    "\n",
    "Save images according to date and time. All images are going to be in a folder labeled ddmmYYYYHHMMSS (date, month, year, hours, minutes, seconds). All images are labeled using the scheme `{location #}\\_{camera #}\\_{b for base else a for annotated}`.\n",
    "\n",
    "_Example: 0_0_b.jpg means location 0, camera 0, base_\n",
    "\n",
    "In the same folder, info on location and camera setup can be found in the file `setup.txt`.\n",
    "\n",
    "The folder will be created in the present working directory (pwd). Specify where to save folder in `path` parameter relative to the pwd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S8egIACLOPvo",
   "metadata": {
    "id": "S8egIACLOPvo"
   },
   "outputs": [],
   "source": [
    "def save_images(paired_images, path: str = None):\n",
    "  folder_name = datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "  if path:\n",
    "    folder = Path(path) / folder_name\n",
    "  else:\n",
    "    folder = Path(folder_name)\n",
    "  folder.mkdir(parents = True, exist_ok = True)\n",
    "  for i in paired_images:\n",
    "    paired_images[i][\"base\"].save(folder / (i + \"_b.png\"))\n",
    "    paired_images[i][\"annotated\"].save(folder / (i + \"_a.png\"))\n",
    "  return folder_name\n",
    "\n",
    "folder_name = save_images(paired_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14390ef0-d1b6-4c27-8936-eb401e0c33a1",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Base Image:\n",
    "\n",
    "<img src=\"images/0_0_b.png\"  width=\"20%\" height=\"20%\" />\n",
    "\n",
    "Annotated Image:\n",
    "\n",
    "<img src=\"images/0_0_a.png\"  width=\"20%\" height=\"20%\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cGdS06AydkUd",
   "metadata": {
    "id": "cGdS06AydkUd"
   },
   "source": [
    "# Complete data collection flow\n",
    "\n",
    "This is a shorthand for what is above without the function definitions. Use this as a quick guide / how-to-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vdeh4rwedzBC",
   "metadata": {
    "id": "Vdeh4rwedzBC"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from beamngpy import BeamNGpy, Scenario, Vehicle\n",
    "from beamngpy.sensors import Camera\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import beamngpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Setup variables\n",
    "home_dir = r'C:\\Users\\jazzy\\Desktop\\BeamNG'\n",
    "user_dir = r'C:\\Users\\jazzy\\Desktop\\BeamNG'\n",
    "\n",
    "# Scenario variables\n",
    "map = 'rb_ks_monza'\n",
    "car_model = 'etk800'\n",
    "start_pos = (-177.105, -107.766, 154.945)\n",
    "start_rot_quat = (0, 0, -0.998, 0.0598)\n",
    "\n",
    "# BeamNG.* instance (server)\n",
    "bng = BeamNGpy('localhost', 64526, home=home_dir, user=user_dir)\n",
    "bng.open()\n",
    "\n",
    "# Scenario for recording\n",
    "scenario = Scenario(map, \"record points\")\n",
    "car0 = Vehicle('car0', model=car_model)\n",
    "scenario.add_vehicle(car0, pos=start_pos, rot_quat=start_rot_quat)\n",
    "scenario.make(bng)\n",
    "bng.scenario.load(scenario)\n",
    "bng.scenario.start()\n",
    "\n",
    "# wait\n",
    "input(\"Press Enter to start recording...\")\n",
    "\n",
    "# Record points\n",
    "recorded_points = record_points_from_car(car0)\n",
    "\n",
    "# Create list of locations and directions to capture images on the track\n",
    "n = 10\n",
    "locations = [generate_random_point(recorded_points) for _ in range(n)]\n",
    "\n",
    "# Attach cameras to car\n",
    "camera_positions = [\n",
    "    ((-0.3, 1, 2), (0, -1, 0), (0, 0, 1), 70)\n",
    "]\n",
    "cameras = attach_cameras(camera_positions, car0)\n",
    "\n",
    "# Generate base images\n",
    "base_images = generate_images(car0, locations, cameras)\n",
    "\n",
    "# wait\n",
    "input(\"Switch track for annotation mode. Press Enter when complete...\")\n",
    "\n",
    "# Generate annotated images (MAKE SURE TO SWITCH TRACK)\n",
    "annotated_images = generate_images(car0, locations, cameras, annotated = True)\n",
    "\n",
    "# Pair images\n",
    "paired_images = pair_images(base_images, annotated_images)\n",
    "\n",
    "# Save images\n",
    "folder_name = save_images(paired_images)\n",
    "\n",
    "print(\"Images saved in folder {}\".format(folder_name))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a3135a35-dc27-4d1a-9003-9d7cb2373010"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
